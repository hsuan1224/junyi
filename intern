#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Jan 14 15:10:52 2019

@author: ads
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from keras.models import Sequential
from keras import layers
from keras.layers.core import Dense,Activation,Dropout
from keras import backend as K
from keras import optimizers
from keras.utils import plot_model
import os

##建立output資料夾##
symbol = 2330
outputdir =  u'/home/ads/桌面/abc/CNNLSTM_out%s/' %symbol
def MkDir():
    os.mkdir(outputdir)
    path = outputdir
    output_lookback = 1440
    output_CNNLSTM_filename = path + 'lookback_%s' % str(output_lookback)
    os.mkdir(output_CNNLSTM_filename)
    output_CNNLSTM_predict = path + 'lookback_%s/predict' % str(output_lookback)
    os.mkdir(output_CNNLSTM_predict)
    output_CNNLSTM_val_loss = path + 'lookback_%s/val_loss' % str(output_lookback)
    os.mkdir(output_CNNLSTM_val_loss)
    output_CNNLSTM_structure = path + 'lookback_%s/structure' % str(output_lookback)
    os.mkdir(output_CNNLSTM_structure)       
MkDir()


#####################################################################################
###下載數據###

#設定資料路徑，讀取資料
data_dir = '/home/ads/桌面/abc'
data_file = os.path.join(data_dir, 'jena_climate_2009_2016.csv')

view = pd.read_csv(data_file,encoding = 'utf8')

#以文件方式讀取資料
f = open(data_file)
data = f.read()
f.close()

#每一筆用換行符號('\n')切開,注意資料筆數
lines = data.split('\n')

#第一列為變數名稱用逗號切開
header = lines[0].split(',')

#資料從第二列開始,注意資料筆數
lines = lines[1:]

#Parsing the data 建立符合資料大小的0矩陣並填入資料
float_data = np.zeros((len(lines),13))
for i, line in enumerate(lines):
    values = [float(x) for x in line.split(',')[1:len(header)]]
    float_data[i, :] = values

#####################################################################################
###資料標準化及預處理###

#數據標準化
mean = float_data[:].mean(axis=0)
float_data -= mean
std = float_data[:].std(axis=0)
float_data /= std


#Generate yielding timeseries samples and their targets 生成samples,targets
def sampling(data,lookback,delay,min_index,max_index,step,sample_size,shuffle=False): #建立一個生成函數
    if max_index is None:
        max_index = len(data) - delay - 1
    
    i = min_index + lookback
 
    if shuffle:  #打亂數據
        rows = np.random.randint(min_index + lookback, max_index, size=sample_size)
    else: 
        if i + sample_size >= max_index: 
            i = min_index + lookback
        rows = np.arange(i, min(i + sample_size, max_index))
        i += len(rows)     
    samples = np.zeros((len(rows), lookback // step, data.shape[-1]-1)) 
    targets = np.zeros((len(rows),))
    for j, row in enumerate(rows):
        indices = range(rows[j] - lookback, rows[j], step) 
        samples[j] = data[indices,1:] #輸出samples
        targets[j] = data[rows[j] + delay][0] #輸出targets
    return samples, targets #函數輸出samples,targets


########################################################################################
###建立模型###

def build_CNNLSTM(units_set, drop_out, train_set,train_target,val_set,val_target,test_set,test_target):       
    history=[]
    evaluate=[]
    pred=[]
    val_loss=[]
    for units in units_set:
        for dropout in drop_out:
            
          model = Sequential()
          model.add(layers.GRU(32,
                     dropout=0.1,
                     recurrent_dropout=0.5,
                     return_sequences=True,
                     input_shape=(None, float_data.shape[-1]-1)))
          model.add(layers.GRU(units=units, activation='relu',
                     dropout=0.1, 
                     recurrent_dropout=dropout))
          model.add(layers.Dense(1))         
           
          adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08) #調整優化器參數
          model.compile(optimizer=adam, loss='mae')  #編譯模型以供訓練
          fit = model.fit(x=train_set, y=train_target, 
                            batch_size=100, epochs=1,validation_data=(val_set,val_target)) #訓練模型
          
          history.append(fit)
           
          if val_set.all() !=np.nan:
               val_loss.append(fit.history['val_loss'][-1]) #輸出val_loss
            
          result = model.evaluate(x=test_set, y=test_target,batch_size=32) #計算輸出模型的誤差
          evaluate.append(result)
            
          predict = model.predict(test_set,batch_size=32)  #輸出預測值
          pred.append(predict)
    return (model, history, val_loss, evaluate, pred)


###########################################################################################################

### experiment ###
##Training
def Training(NN,lookback,t_train_min,t_train_max,t_train_size,t_val_min,t_val_max,t_val_size,t_test_min,t_test_max,t_test_size):
    for i in range(10):
        if t_train_min-i*300>0:
            if NN=='CNNLSTM':
                delay = 144
                train_set,train_target=sampling(float_data,lookback,delay,t_train_min-i*300,t_train_max-i*300,6,t_train_size,True) #生成train的samples,targets
                val_set,val_target=sampling(float_data,lookback,delay,t_val_min-i*300,t_val_max-i*300,6,t_val_size,False) #生成validation的samples,targets
                test_set,test_target=sampling(float_data,lookback,delay,t_test_min-i*300,t_test_max-i*300,6,t_test_size,False) #生成test的samples,targets
                model,history,val_loss,evaluate,pred = build_CNNLSTM([1,32,64],[0.2,0.4,0.5],train_set,train_target,val_set,val_target,test_set,test_target) #輸入資料訓練模型
                #convert val_loss to a dataframe
                val= np.zeros((3, 3))
                j=0
                for ind in range(0,len(val_loss),3): #輸出3*3的val_loss
                    val[j,:]=val_loss[ind:ind+3] 
                    j+=1
                val=pd.DataFrame(val)
                val.columns = ['0.2','0.4','0.5'] 
                val.index = ['1','32','64']  
                #write to csv
                val.to_csv(outputdir + 'lookback_%d/val_loss/%d.csv'%(lookback,i),float_format='%.6f',header=True,index=True)
            del model,evaluate,pred
            print('     ------------Traing turn=%d---------------     '%i)     
  
##Testing
def Testing(NN,units,output,dropout,lookback,te_train_min,te_train_max,te_train_size,te_test_min,te_test_max,te_test_size):
    ev=[]
    #rmse=[]
    for i in range(10):
        if te_train_min-i*300>0:
            if NN=='CNNLSTM':
                delay = 144
                train_set,train_target=sampling(float_data,lookback,delay,te_train_min+330-i*300,te_train_max+330-i*300,6,te_train_size,False)  
                test_set,test_target=sampling(float_data,lookback,delay,te_test_min-i*300,te_test_max-i*300,6,te_test_size,False)
                #test的時候不需要validation
                val_target = np.zeros((300)) 
                val_target[val_target==0]=np.nan
                val_set = np.zeros((300,lookback//6,12))
                val_set[val_set==0]=np.nan
                model,history,val_loss,evaluate,pred = build_CNNLSTM([units[i]],[dropout[i]],train_set,train_target,val_set,val_target,test_set,test_target)  
            #save evaluations in ev
            ev.append(evaluate)
            p=pred[0].reshape(1000,)   
            
            #restore data to original form
            result = np.vstack((test_target,p))
            result = pd.DataFrame(result)
            result = result.transpose()
            result.columns = ['real','predict']
            result = result*std[0]+mean[0]
            #rmse.append(np.mean(np.sqrt(result.loc[:,'real']-result.loc[:,'predict'])))
            #rmse = pd.DataFrame(rmse)
            #write to csv
            if NN=='CNNLSTM':
                result.to_csv(outputdir + 'lookback_%d/predict/%s_lstm_lb=%d_result_%d.csv'%(lookback,file_name,lookback,i),float_format='%.4f',header=True,index=False)
                print("We finish building the model")
                plot_model(model, to_file=outputdir + 'lookback_%d/structure/lstm_model%d.png'%(lookback,i), show_layer_names=False,show_shapes=True)
            del val_loss
            print('     ------------Testing turn=%d---------------     '%i) 
            

############################################################################################################

lookback = 1440
delay = 144

cltest_size=1000
cltest_max=len(float_data)-1
cltest_min=cltest_max-delay-cltest_size-lookback

clval_size=1000
clval_max=cltest_max-delay-cltest_size
clval_min=clval_max-delay-clval_size-lookback

cltrain_size=2000
cltrain_max=clval_max-delay-clval_size
cltrain_min=cltrain_max-delay-cltrain_size-lookback

import time
start = time.time()

Training('CNNLSTM',lookback,cltrain_min,cltrain_max,cltrain_size,clval_min,clval_max,clval_size,cltest_min,cltest_max,cltest_size)

end = time.time()
running_time = end-start
print('time taken',running_time,'seconds') 
#2hr43mins
#time taken 9777.729731559753 seconds



units=[64,1,32,64,32,64,32,32,32,32]
dropout=[0.2,0.4,0.5,0.4,0.4,0.5,0.2,0.5,0.5,0.4]
file_name='2330'

start = time.time()

Testing('CNNLSTM',units,None,dropout,lookback,cltrain_min,cltrain_max,cltrain_size,cltest_min,cltest_max,cltest_size)

end = time.time()
running_time = end-start
print('time taken',running_time,'seconds')
#22mins
#time taken 1302.8725910186768 seconds

###########################################################################

#RMSE
from sklearn.metrics import mean_squared_error
from math import sqrt
import pandas as pd
import numpy as np

file_name='2330'
def RMSE (file_name):

            qaz=["a0","a1","a2","a3","a4","a5","a6","a7","a8","a9"]
            rmse= np.zeros(10)
            for i in range(10):
                  for a in qaz:
                        a= pd.read_csv('/home/ads/桌面/abc/CNNLSTM_out2330/lookback_%d/predict/%s_lstm_lb=%d_result_%d.csv'%(lookback,file_name,lookback,i))
                        rmse[i]=sqrt(mean_squared_error(a.real, a.predict))
            rmse=pd.DataFrame(rmse)
            rmse.to_csv('/home/ads/桌面/abc/CNNLSTM_out2330/lookback_%d/predict/%s_lstm_lb=%d_rmseALL.csv'%(lookback,file_name,lookback),float_format='%.4f',header=False,index=True)
    
RMSE(file_name)



########################################################################################################################################

'''
import matplotlib.pyplot as plt

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

'''




















